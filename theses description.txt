i am a Masters student of Mechanical Engineering at Linkoping University, Sweden.
Currently, i am undertaking my Masters Thesis at the product Realisation Division of the department of Management and Engineering, IEI, of the University.
Thesis topic: Integrating Computer Vision, Large Language Models and Robot Control for Personalised (Task Planning and) Execution in Virtual Environments (eg NVIDIA Omniverse Isaac Sim).

I want to write an inteligent, interesting and compelling literature review chapter (Discusses existing research and identifies gaps) for my thesis report.
- I need to include all the essentials that would make it an interesting read for any student, academician, professor (supervisor and examiner alike) that finds and reads my report.

- The literature review has to be formal and professional, but also have all the spices needed to curate an interesting report, having the best qualities of a perfect thesis report literaturre review section; including but not limited to: Strong Research Foundation, Backed by a thorough literature review and Provides a theoretical framework that aligns with the research problem, and also a Logical Flow and Coherence

Attached is the thesis proposal and a planning report i made at the start of the project. Basically this is what i am trying to do in the project: 
- prior to now, we have a digital twin of a robot (ABB Yumi cobot in this case) in Omniverse isaac sim (simulation and physical) that has been successfully integrated with a camera vision functionality, whereby a camera has been used to capture images of a scene in realtime, and through ROS, the cordinates and other properties of object in scene has been sent to the robot control script enabling it to conduct precise object manipullation for pick and place operations.
- Now,  due to the complexity of the process, my thesis basically want to implement an SQL-based modular approach to enable the inclusion and implementation of other/more robot tasks like screwing, travel, pick, drop etc
- so with a knowledge base in SQLite database, the camera can understand and store object properties of the scene in tables in the database, then the robot script can thereby  query these table to retrieve data for its execution.
- also, user profiles/data can be stored in the database to enable personalisation of task plans and executions (incluing role base, authentication (face and voice), storage of historical interactions, skill library, etc
- LLM(s) can then also be integrated for language understanding and processing of user commands and instructions enabling users to interact with the robot using natural language and  gesture cues also.  LLMs interprete these cues in text format, but capture via a video stream and transcribe these voice commands, merging them with previous interaction history and/or preferences into a user-centric context-aware form, before storing them in formats considering also the pre-trained skill library of the robot (in the database) to plan and store required data for robot task execution.
- the virtual robot in Omniverse isaac sim retrieves needed data from the database and executes task in the virtual siulation environment. Then the physical twin of the robot mimics the task to execute the task in real life real-time.